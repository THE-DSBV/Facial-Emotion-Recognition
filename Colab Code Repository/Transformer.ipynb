{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15346,"status":"ok","timestamp":1723171725467,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"-IIQSIfmflxA"},"outputs":[],"source":["from zipfile import ZipFile\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import Subset\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import shutil\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling1D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","# ViT specific imports\n","from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Add\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_z0gjyntd9zV"},"outputs":[],"source":["#Testing with basic transformer (From lecture)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1723164736066,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"xk22GCfsfPnG"},"outputs":[],"source":["#Encoder\n","class TransformerEncoder(nn.Module):\n","  def __init__(self, input_size, hidden_size):\n","    super(TransformerEncoder, self).__init__()\n","    self.linear_q = nn.Linear(input_size, hidden_size)\n","    self.linear_k = nn.Linear(input_size, hidden_size)\n","    self.linear_v = nn.Linear(input_size, hidden_size)\n","    self.linear_x = nn.Linear(input_size, hidden_size)\n","    self.attention = nn.MultiheadAttention(hidden_size, num_heads=4, batch_first=True)\n","    self.fc = nn.Sequential(\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_size, hidden_size))\n","    self.norm = nn.LayerNorm(hidden_size)\n","  def forward(self, x):\n","    q, k, v = self.linear_q(x), self.linear_k(x), self.linear_v(x)\n","    x = self.norm(self.linear_x(x) + self.attention(q, k, v))\n","    x = self.norm(x + self.fc(x))\n","    return x"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"eo98VIZ3fqwS","executionInfo":{"status":"ok","timestamp":1723164736067,"user_tz":240,"elapsed":12,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"}}},"outputs":[],"source":["#Classifier\n","class TweetTransformer(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_class):\n","    super(TweetTransformer, self).__init__()\n","    self.emb = nn.Embedding.from_pretrained(glove.vectors)\n","    self.encoder = TransformerEncoder(input_size, hidden_size)\n","    self.fc = nn.Linear(hidden_size, num_class)\n","  def forward(self, x, pos):\n","    # Add GloVe vectors to positional encoding\n","    x = self.emb(x) + pos\n","    x = self.encoder(x)\n","    # Add embeddings from transformer encoding to get tweet embedding\n","    x = torch.sum(x, -1)\n","    # Classify\n","    return self.fc(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRrtfA0ErgSr"},"outputs":[],"source":["#Real Transformer"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":195,"status":"ok","timestamp":1723171730625,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"IE93ArzFhSRI"},"outputs":[],"source":["class PatchEmbedding(layers.Layer):\n","    def __init__(self, image_size, patch_size, projection_dim):\n","        super(PatchEmbedding, self).__init__()\n","        self.image_size = image_size\n","        self.patch_size = patch_size\n","        self.projection_dim = projection_dim\n","        self.num_patches = (image_size // patch_size) ** 2\n","        self.projection = tf.keras.layers.Dense(projection_dim)\n","        self.position = self.add_weight(\n","            name=\"position_embeddings\",\n","            shape=(1, self.num_patches, projection_dim),\n","            initializer='random_normal'\n","        )\n","\n","    def call(self, patches):\n","        batch_size = tf.shape(patches)[0]\n","        # Extract patches\n","        patches = tf.image.extract_patches(\n","            images=patches,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding='VALID'\n","        )\n","        # Flatten the patches\n","        patch_dim = patches.shape[-1]\n","        patches = tf.reshape(patches, (batch_size, self.num_patches, patch_dim))\n","        embeddings = self.projection(patches)\n","        embeddings = tf.cast(embeddings, dtype=tf.float32)\n","        position = tf.cast(self.position, dtype=tf.float32)\n","        return embeddings + position\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISDHwg_PrjFi"},"outputs":[],"source":["#Patch embedding layer\n","'''class PatchEmbedding(layers.Layer):\n","  def __init__(self, num_patches, projection_dim):\n","    super(PatchEmbedding, self).__init__()\n","    self.num_patches = num_patches\n","    self.projection = tf.keras.layers.Dense(projection_dim)\n","    self.position = self.add_weight(name=\"position_embeddings\",\n","            shape=(1, num_patches, projection_dim),\n","            initializer='random_normal')\n","    #self.position = self.add_weight(\"position_embeddings\", )\n","\n","  def call(self, patches):\n","    embeddings = self.projection(patches)\n","      # Ensure that position embeddings are the correct dtype\n","    embeddings = tf.cast(embeddings, dtype=tf.float32)\n","    position = tf.cast(self.position, dtype=tf.float32)\n","    return embeddings + position\n","'''\n","\n","  ''' def __init__(self, num_patches, projection_dim):\n","    super(PatchEmbedding, self).__init__()\n","    self.num_patches = num_patches\n","    self.projection = layers.Dense(units=projection_dim)\n","    self.position = tf.Variable(initial_value = tf.random.normal([1, num_patches, projection_dim]), trainable=True)\n","\n","  def call(self, patches):\n","    embeddings = self.projection(patches)\n","    # Reshape embeddings to match position embeddings\n","    #embeddings = tf.reshape(embeddings, [-1, self.num_patches, self.projection.units])\n","    return embeddings + self.position # Add position embeddings after reshaping\n","'''\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":224,"status":"ok","timestamp":1723171734539,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"eDToPuqkrlkf"},"outputs":[],"source":["#Encoder Layer\n","class TransformerEncoderLayer(layers.Layer):\n","  def __init__(self, num_heads, embedding_dim, mlp_dim, dropout_rate=0.1):\n","    super(TransformerEncoderLayer, self).__init__()\n","    self.layer_norm1 = LayerNormalization()\n","    self.multi_head_attention = MultiHeadAttention(num_heads, embedding_dim)\n","    self.add1 = Add()\n","    self.layer_norm2 = layers.LayerNormalization()\n","    self.mlp = models.Sequential([\n","      layers.Dense(mlp_dim, activation='relu'),\n","      layers.Dense(embedding_dim)])\n","    self.add2 = Add()\n","    self.dropout = Dropout(dropout_rate)\n","\n","  def call(self, x):\n","    #multi head attention\n","    x1 = self.layer_norm1(x)\n","    attention_output = self.multi_head_attention(x1,x1)\n","    x2 = self.add1([x, attention_output])\n","\n","    #FF network\n","    x3 = self.layer_norm2(x2)\n","    x3 = self.mlp(x3)\n","    x4 = self.add2([x2, x3])\n","    return self.dropout(x4)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1723171736983,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"iwb8qIJ3zH5G"},"outputs":[],"source":["#Vision Transformer Model\n","def vit_model(image_size, patch_size, num_layers, num_heads, projection_dim, mlp_dim, dropout_rate, num_classes):\n","  num_patches = (image_size // patch_size) ** 2\n","  inputs = layers.Input(shape=(image_size, image_size, 3))\n","  #projection_dim = (patch_size * patch_size * 3)\n","\n","  #patches = PatchEmbedding(num_patches, projection_dim)(inputs)\n","\n","  #patches = PatchEmbedding((num_patches, (patch_size * patch_size * 3)))(inputs)\n","\n","  #Patch embedding\n","  x = PatchEmbedding(image_size, patch_size, projection_dim)(inputs)#(patches)\n","\n","  #Transformer encoding\n","  for _ in range(num_layers):\n","    x = TransformerEncoderLayer(num_heads, projection_dim, mlp_dim, dropout_rate)(x)\n","\n","  #Classification head\n","  x = LayerNormalization()(x)\n","  #x = Flatten()(x)\n","  x = GlobalAveragePooling1D()(x)\n","  x = Dense(mlp_dim, activation='relu')(x)\n","  x = Dropout(dropout_rate)(x)\n","  outputs = Dense(num_classes, activation='softmax')(x)\n","\n","  #Model\n","  model = models.Model(inputs=inputs, outputs=outputs)\n","  return model\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2414,"status":"ok","timestamp":1723171741951,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"JDfHqzsk3qFl"},"outputs":[],"source":["#hyperparameters\n","image_size = 224 #Make sure\n","patch_size = 32\n","num_layers = 8\n","num_heads = 16\n","projection_dim = 256\n","mlp_dim = 256\n","dropout_rate = 0.1\n","num_classes = 7\n","\n","model = vit_model(image_size, patch_size, num_layers, num_heads, projection_dim, mlp_dim, dropout_rate, num_classes)\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1087,"status":"ok","timestamp":1723171745118,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"3ui-I4ecJNRe","outputId":"bcfb8f30-b511-4036-aef1-466c0448362e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iN50V_JKWhBQ","executionInfo":{"status":"ok","timestamp":1723172752770,"user_tz":240,"elapsed":650903,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"}},"outputId":"5b684ae4-376a-4cd2-b2f5-8e2e79b6f08b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7178 files belonging to 7 classes.\n","Using 5743 files for training.\n","Found 7178 files belonging to 7 classes.\n","Using 1435 files for validation.\n","Epoch 1/10\n","\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 283ms/step - accuracy: 0.2142 - loss: 1.8940 - val_accuracy: 0.1861 - val_loss: 1.7982\n","Epoch 2/10\n","\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 236ms/step - accuracy: 0.2366 - loss: 1.8233 - val_accuracy: 0.2314 - val_loss: 1.7794\n","Epoch 3/10\n","\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 212ms/step - accuracy: 0.2476 - loss: 1.8154 - val_accuracy: 0.2530 - val_loss: 1.7656\n","Epoch 4/10\n","\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 67ms/step - accuracy: 0.2547 - loss: 1.8097 - val_accuracy: 0.2523 - val_loss: 1.7709\n","Epoch 5/10\n","\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 67ms/step - accuracy: 0.2518 - loss: 1.8096 - val_accuracy: 0.2564 - val_loss: 1.7762\n","Epoch 6/10\n","\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 65ms/step - accuracy: 0.2489 - loss: 1.8042 - val_accuracy: 0.2390 - val_loss: 1.7782\n","\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2286 - loss: 1.7918\n","Test Loss: 1.7782, Test Accuracy: 0.2390\n"]}],"source":["dataset_path = '/content/gdrive/MyDrive/APS360 Project/Data/test'\n","\n","batch_size = 8\n","\n","# Load datasets with optimized pipeline\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    dataset_path,\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=123,\n","    image_size=(224,224),\n","    batch_size=batch_size,\n","    label_mode = 'categorical'\n",").cache().prefetch(tf.data.experimental.AUTOTUNE)\n","\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    dataset_path,\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=123,\n","    image_size=(224,224),\n","    batch_size=batch_size,\n","    label_mode = 'categorical'\n",").cache().prefetch(tf.data.experimental.AUTOTUNE)\n","\n","\n","# Mixed precision\n","from tensorflow.keras import mixed_precision\n","policy = mixed_precision.Policy('mixed_float16')\n","mixed_precision.set_global_policy(policy)\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","#train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, num_classes, axis=-1))) # Add axis=-1\n","#val_ds = val_ds.map(lambda x, y: (x, tf.one_hot(y, num_classes, axis=-1))) # Add axis=-1\n","\n","# Train the model\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=10,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n","        tf.keras.callbacks.ModelCheckpoint('vit_model.keras', save_best_only=True),\n","        tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)\n","    ]\n",")\n","\n","# Evaluate the model\n","test_loss, test_accuracy = model.evaluate(val_ds)\n","print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n","\n","# Save the model\n","model.save('vit_model.keras')"]},{"cell_type":"code","source":["import gc\n","def reset_ram():\n","    gc.collect()  # Garbage collection to free up RAM\n","    torch.cuda.empty_cache()  # Clear GPU cache\n","\n","# Call this function in between training sessions\n","reset_ram()\n","\n","from tensorflow.keras.backend import clear_session\n","clear_session()"],"metadata":{"id":"ITG3eDqhib4X","executionInfo":{"status":"ok","timestamp":1723163805839,"user_tz":240,"elapsed":692,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"elapsed":664,"status":"error","timestamp":1723144100673,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"ycbzlPyPW_Vq","outputId":"491dba84-0e0e-4ffd-ce63-a00f8e1b9e83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'items'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-41de7fbd35aa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     callbacks=[\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py\u001b[0m in \u001b[0;36m_pythonify_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"]}],"source":["history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=10,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n","        tf.keras.callbacks.ModelCheckpoint('vit_model.keras', save_best_only=True),\n","        tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6536,"status":"ok","timestamp":1723142211586,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"8vRc--GxRuQt","outputId":"956dfea5-f70d-43e2-fb9b-b31d99e0ff58"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n","Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n"]}],"source":["%pip install split-folders\n","import splitfolders"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207834,"status":"ok","timestamp":1723142802279,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"ZsJvX7qARqil","outputId":"eadf898c-66f0-4ec9-9d56-e43fb68c69ba"},"outputs":[{"name":"stderr","output_type":"stream","text":["Copying files: 7178 files [03:27, 34.56 files/s] \n"]}],"source":["splitfolders.ratio('/content/gdrive/MyDrive/APS360 Project/Data/test', output=\"split_data\",\n","    seed=999, ratio=(0.8, 0.1, 0.1), group_prefix=None, move=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TU9NsCy0UTSB"},"outputs":[],"source":["transform = transforms.Compose(\n","        [transforms.ToTensor(),transforms.Resize((48,48))])\n","\n","#transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224,224))])\n","\n","#Create train, validation, and testing datasets\n","#Apply the transformations\n","train_data = ImageFolder(\"/content/split_data/train\", transform)\n","val_data = ImageFolder(\"/content/split_data/val\", transform)\n","test_data = ImageFolder(\"/content/split_data/test\", transform)\n","\n","#Load all of the datasets into their respective loaders\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=10,\n","                                           shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_data, batch_size=10,\n","                                         shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=10,\n","                                          shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"elapsed":210,"status":"error","timestamp":1723143155111,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"gF1AonmAVZ9A","outputId":"e6a4ff17-1e27-4e6f-d908-6a9f48224faa"},"outputs":[{"ename":"AttributeError","evalue":"'Functional' object has no attribute 'parameters'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-32d2a9dce0a9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = TransformerModel(input_dim=..., hidden_dim=..., output_dim=..., num_heads=..., num_layers=...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'parameters'"]}],"source":["#model = TransformerModel(input_dim=..., hidden_dim=..., output_dim=..., num_heads=..., num_layers=...)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_loader:\n","        src, tgt = batch  # Assuming your DataLoader returns a tuple (src, tgt)\n","        optimizer.zero_grad()\n","        output = model(src, tgt)\n","        loss = criterion(output.view(-1, output.shape[-1]), tgt.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16759,"status":"ok","timestamp":1723141729691,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"1StOJ4tpJDSC","outputId":"078f3105-cbc6-4e93-e132-16e1c9b84c95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 28274 files belonging to 6 classes.\n","Found 7178 files belonging to 7 classes.\n"]}],"source":["'''\n","#Load data for transformer (different format then for CNN???)\n","train_dir = '/content/gdrive/MyDrive/APS360 Project/Data/train'\n","test_dir = '/content/gdrive/MyDrive/APS360 Project/Data/test'\n","\n","train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_dir,\n","    image_size=(48, 48),  # Match with your model input size\n","    batch_size=32,\n","    label_mode='int',  # Adjust based on your labels\n","    shuffle=True\n",")\n","\n","# Load test data\n","test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","    test_dir,\n","    image_size=(48, 48),\n","    batch_size=32,\n","    label_mode='int'\n",")'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"elapsed":29118,"status":"ok","timestamp":1723141936122,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"tfvpIATuKPdF","outputId":"547f6f56-db7a-4f2e-8ac8-d40f1a77a573"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nsubset_size = 100  # Adjust this value to the desired subset size\\ntrain_data = train_dataset.take(subset_size).map(lambda x, y: (normalization_layer(x), to_categorical(y, num_classes=num_classes)))\\ntest_data = test_dataset.take(subset_size).map(lambda x, y: (normalization_layer(x), to_categorical(y, num_classes=num_classes)))\\n\\ntrain_data = train_data.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\\ntest_data = test_dataset.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\\n#train_data = train_data.take(100)\\n#test_data = test_data.take(100)'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["'''normalization_layer = tf.keras.layers.Rescaling(1./255)\n","\n","subset_size = 10  # Adjust this value to the desired subset size\n","batch_size = 32  # Use smaller batches to manage memory\n","\n","# Create subsets and preprocess the data\n","train_data = train_dataset.take(subset_size).map(lambda x, y: (normalization_layer(x), to_categorical(y, num_classes=num_classes)))\n","test_data = test_dataset.take(subset_size).map(lambda x, y: (normalization_layer(x), to_categorical(y, num_classes=num_classes)))\n","\n","# Optimize the dataset pipeline\n","train_data = train_data.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","test_data = test_data.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","# Clear memory\n","import gc\n","gc.collect()\n","'''\n","'''\n","subset_size = 100  # Adjust this value to the desired subset size\n","train_data = train_dataset.take(subset_size).map(lambda x, y: (normalization_layer(x), to_categorical(y, num_classes=num_classes)))\n","test_data = test_dataset.take(subset_size).map(lambda x, y: (normalization_layer(x), to_categorical(y, num_classes=num_classes)))\n","\n","train_data = train_data.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","test_data = test_dataset.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","#train_data = train_data.take(100)\n","#test_data = test_data.take(100)'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"elapsed":192,"status":"error","timestamp":1723142898678,"user":{"displayName":"Duncan Volk","userId":"15461499935065026162"},"user_tz":240},"id":"-mO-8G3OKV-W","outputId":"27246fd4-be27-43a7-baba-8c5297744b61"},"outputs":[{"ename":"ValueError","evalue":"When providing `x` as a torch DataLoader, `y` should not be passed. Instead, the targets should be included as part of the torch DataLoader.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-cc8af85ea5e9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mraise_unsupported_arg\u001b[0;34m(arg_name, arg_description, input_type)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_unsupported_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;34mf\"When providing `x` as a {input_type}, `{arg_name}` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34mf\"should not be passed. Instead, {arg_description} should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: When providing `x` as a torch DataLoader, `y` should not be passed. Instead, the targets should be included as part of the torch DataLoader."]}],"source":["# Enable eager execution to create variables on subsequent calls\n","tf.config.run_functions_eagerly(True)\n","\n","model.fit(\n","    train_loader,\n","    val_loader,\n","    epochs=20\n",")"]},{"cell_type":"markdown","metadata":{"id":"IAtEqbno0mn-"},"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPh/gpzDV/oAmBinOqOHdfV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}